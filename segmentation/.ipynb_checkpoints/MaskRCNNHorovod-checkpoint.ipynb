{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: mlserviceworkspace\n",
      "Azure region: westus2\n",
      "Subscription id: 601f4351-33bb-4d76-96ca-886940409b3d\n",
      "Resource group: mlserviceworkspace\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "script_folder = './mask_rcnn_horovod'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "exp = Experiment(workspace=ws, name='mask_rcnn_horovod_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "blob_datastore_name='isic2018' # Name of the Datastore  to workspace\n",
    "container_name=os.getenv(\"BLOB_CONTAINER\", \"isic2018\") # Name of Azure blob container\n",
    "account_name=os.getenv(\"BLOB_ACCOUNTNAME\", \"mlblobdatastore\") # Storage account name\n",
    "account_key=os.getenv(\"BLOB_ACCOUNT_KEY\", \"bPlInBOqf0kfPpSNYeemRKNiOfcWsMWAUfR3ieyTUpxBKn/FEkZG9RgHUQfVjNtI3ky32wZ+LrjCe/oVC9M2eg==\") # Storage account key\n",
    "\n",
    "blob_datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                         datastore_name=blob_datastore_name, \n",
    "                                                         container_name=container_name, \n",
    "                                                         account_name=account_name,\n",
    "                                                         account_key=account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "#get named datastore from current workspace\n",
    "datastore = Datastore.get(ws, datastore_name='isic2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "\n",
    "datastore_paths = [\n",
    "                  (datastore, 'ISIC2018_Task1-2_Training_Input'),(datastore, 'ISIC2018_Task1_Training_GroundTruth')\n",
    "                 ]\n",
    "\n",
    "isic_ds_training = Dataset.File.from_files(path=datastore_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new version of titanic_ds\n",
    "isic_ds = isic_ds_training.register(workspace = ws,\n",
    "                                 name = 'isic_ds',\n",
    "                                 description = 'isic training data',\n",
    "                                 create_new_version = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, 'isic_ds')\n",
    "\n",
    "# list the files referenced by mnist dataset\n",
    "dataset.to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# USAGE\n",
      "# python lesions.py --mode train\n",
      "# python lesions.py --mode investigate\n",
      "# python lesions.py --mode predict \\\n",
      "# \t--image isic2018/ISIC2018_Task1-2_Training_Input/ISIC_0000000.jpg\n",
      "\n",
      "# import the necessary packages\n",
      "from imgaug import augmenters as iaa\n",
      "from mrcnn.config import Config\n",
      "from mrcnn import model as modellib\n",
      "from mrcnn import utils\n",
      "from imutils import paths\n",
      "import numpy as np\n",
      "import argparse\n",
      "import imutils\n",
      "import random\n",
      "import cv2\n",
      "import os\n",
      "from mrcnn import visualize\n",
      "import glob\n",
      "from azureml.core import Run\n",
      "\n",
      "\n",
      "\n",
      "# dataset object from the run\n",
      "\n",
      "run = Run.get_context()\n",
      "\n",
      "\n",
      "# construct the argument parser and parse the arguments\n",
      "ap = argparse.ArgumentParser()\n",
      "ap.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
      "ap.add_argument(\"-w\", \"--weights\",\n",
      "    help=\"optional path to pretrained weights\")\n",
      "ap.add_argument(\"-m\", \"--mode\",\n",
      "    help=\"train or investigate\")\n",
      "args = vars(ap.parse_args())\n",
      "\n",
      "data_folder = args[\"data_folder\"]\n",
      "print('Data folder:', data_folder)\n",
      "\n",
      "\n",
      "\n",
      "# get the file paths on the compute\n",
      "\n",
      "IMAGES_PATHS = os.path.join(os.path.abspath(\".\"),data_folder, 'ISIC2018_Task1-2_Training_Input')\n",
      "MASKS_PATHS = os.path.join(os.path.abspath(\".\"),data_folder, 'ISIC2018_Task1_Training_GroundTruth')\n",
      "\n",
      "\n",
      "print(\"#################################################\")\n",
      "print(IMAGES_PATHS)\n",
      "print(\"#################################################\")\n",
      "print(MASKS_PATHS)\n",
      "\n",
      "# initialize the amount of data to use for training\n",
      "TRAINING_SPLIT = 0.8\n",
      "\n",
      "# grab all image paths, then randomly select indexes for both training\n",
      "# and validation\n",
      "IMAGE_PATHS = sorted(list(paths.list_images(IMAGES_PATHS)))\n",
      "\n",
      "print(\"#################################################\")\n",
      "print(len(IMAGE_PATHS))\n",
      "\n",
      "idxs = list(range(0, len(IMAGE_PATHS)))\n",
      "random.seed(42)\n",
      "random.shuffle(idxs)\n",
      "i = int(len(idxs) * TRAINING_SPLIT)\n",
      "trainIdxs = idxs[:i]\n",
      "valIdxs = idxs[i:]\n",
      "\n",
      "# initialize the class names dictionary\n",
      "CLASS_NAMES = {1: \"lesion\"}\n",
      "\n",
      "# initialize the path to the Mask R-CNN pre-trained on COCO\n",
      "COCO_PATH = \"mask_rcnn_coco.h5\"\n",
      "\n",
      "# initialize the name of the directory where logs and output model\n",
      "# snapshots will be stored\n",
      "\n",
      "LOGS_AND_MODEL_DIR = \"./outputs/lesions_logs\"\n",
      "os.makedirs(LOGS_AND_MODEL_DIR, exist_ok=True)\n",
      "\n",
      "class LesionBoundaryConfig(Config):\n",
      "\t# give the configuration a recognizable name\n",
      "\tNAME = \"lesion\"\n",
      "\n",
      "\t# set the number of GPUs to use training along with the number of\n",
      "\t# images per GPU (which may have to be tuned depending on how\n",
      "\t# much memory your GPU has)\n",
      "\tGPU_COUNT = 1\n",
      "\tIMAGES_PER_GPU = 4\n",
      "\n",
      "\t# set the number of steps per training epoch and validation cycle\n",
      "\tSTEPS_PER_EPOCH = len(trainIdxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
      "\tVALIDATION_STEPS = len(valIdxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
      "\n",
      "\t# number of classes (+1 for the background)\n",
      "\tNUM_CLASSES = len(CLASS_NAMES) + 1\n",
      "\n",
      "class LesionBoundaryInferenceConfig(LesionBoundaryConfig):\n",
      "\t# set the number of GPUs and images per GPU (which may be\n",
      "\t# different values than the ones used for training)\n",
      "\tGPU_COUNT = 1\n",
      "\tIMAGES_PER_GPU = 4\n",
      "    \n",
      "\t# set the number of steps per training epoch and validation cycle\n",
      "\tSTEPS_PER_EPOCH = len(trainIdxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
      "\tVALIDATION_STEPS = len(valIdxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
      "\n",
      "\t# set the minimum detection confidence (used to prune out false\n",
      "\t# positive detections)\n",
      "\tDETECTION_MIN_CONFIDENCE = 0.9\n",
      "\n",
      "class LesionBoundaryDataset(utils.Dataset):\n",
      "\tdef __init__(self, imagePaths, classNames, width=1024):\n",
      "\t\t# call the parent constructor\n",
      "\t\tsuper().__init__(self)\n",
      "\n",
      "\t\t# store the image paths and class names along with the width\n",
      "\t\t# we'll resize images to\n",
      "\t\tself.imagePaths = imagePaths\n",
      "\t\tself.classNames = classNames\n",
      "\t\tself.width = width\n",
      "\n",
      "\tdef load_lesions(self, idxs):\n",
      "\t\t# loop over all class names and add each to the 'lesion'\n",
      "\t\t# dataset\n",
      "\t\tfor (classID, label) in self.classNames.items():\n",
      "\t\t\tself.add_class(\"lesion\", classID, label)\n",
      "\n",
      "\t\t# loop over the image path indexes\n",
      "\t\tfor i in idxs:\n",
      "\t\t\t# extract the image filename to serve as the unique\n",
      "\t\t\t# image ID\n",
      "\t\t\timagePath = self.imagePaths[i]\n",
      "\t\t\tfilename = imagePath.split(os.path.sep)[-1]\n",
      "\n",
      "\t\t\t# add the image to the dataset\n",
      "\t\t\tself.add_image(\"lesion\", image_id=filename,\n",
      "\t\t\t\tpath=imagePath)\n",
      "\n",
      "\tdef load_image(self, imageID):\n",
      "\t\t# grab the image path, load it, and convert it from BGR to\n",
      "\t\t# RGB color channel ordering\n",
      "\t\tp = self.image_info[imageID][\"path\"]\n",
      "\t\timage = cv2.imread(p)\n",
      "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
      "\n",
      "\t\t# resize the image, preserving the aspect ratio\n",
      "\t\timage = imutils.resize(image, width=self.width)\n",
      "\n",
      "\t\t# return the image\n",
      "\t\treturn image\n",
      "\n",
      "\tdef load_mask(self, imageID):\n",
      "\t\t# grab the image info and derive the full annotation path\n",
      "\t\t# file path\n",
      "\t\tinfo = self.image_info[imageID]\n",
      "\t\tfilename = info[\"id\"].split(\".\")[0]\n",
      "\t\tannotPath = os.path.sep.join([MASKS_PATHS,\n",
      "\t\t\t\"{}_segmentation.png\".format(filename)])\n",
      "\n",
      "\t\t# load the annotation mask and resize it, *making sure* to\n",
      "\t\t# use nearest neighbor interpolation\n",
      "\t\tannotMask = cv2.imread(annotPath)\n",
      "\t\tannotMask = cv2.split(annotMask)[0]\n",
      "\t\tannotMask = imutils.resize(annotMask, width=self.width,\n",
      "\t\t\tinter=cv2.INTER_NEAREST)\n",
      "\t\tannotMask[annotMask > 0] = 1\n",
      "\n",
      "\t\t# determine the number of unique class labels in the mask\n",
      "\t\tclassIDs = np.unique(annotMask)\n",
      "\n",
      "\t\t# the class ID with value '0' is actually the background\n",
      "\t\t# which we should ignore and remove from the unique set of\n",
      "\t\t# class identifiers\n",
      "\t\tclassIDs = np.delete(classIDs, [0])\n",
      "\n",
      "\t\t# allocate memory for our [height, width, num_instances]\n",
      "\t\t# array where each \"instance\" effectively has its own\n",
      "\t\t# \"channel\" -- since there is only one lesion per image we\n",
      "\t\t# know the number of instances is equal to 1\n",
      "\t\tmasks = np.zeros((annotMask.shape[0], annotMask.shape[1], 1),\n",
      "\t\t\tdtype=\"uint8\")\n",
      "\n",
      "\t\t# loop over the class IDs\n",
      "\t\tfor (i, classID) in enumerate(classIDs):\n",
      "\t\t\t# construct a mask for *only* the current label\n",
      "\t\t\tclassMask = np.zeros(annotMask.shape, dtype=\"uint8\")\n",
      "\t\t\tclassMask[annotMask == classID] = 1\n",
      "\n",
      "\t\t\t# store the class mask in the masks array\n",
      "\t\t\tmasks[:, :, i] = classMask\n",
      "\n",
      "\t\t# return the mask array and class IDs\n",
      "\t\treturn (masks.astype(\"bool\"), classIDs.astype(\"int32\"))\n",
      "\n",
      "if args[\"mode\"] == \"train\":\n",
      "    # load the training dataset\n",
      "    trainDataset = LesionBoundaryDataset(IMAGE_PATHS, CLASS_NAMES)\n",
      "    trainDataset.load_lesions(trainIdxs)\n",
      "    trainDataset.prepare()\n",
      "\n",
      "    # load the validation dataset\n",
      "    valDataset = LesionBoundaryDataset(IMAGE_PATHS, CLASS_NAMES)\n",
      "    valDataset.load_lesions(valIdxs)\n",
      "    valDataset.prepare()\n",
      "\n",
      "    # initialize the training configuration\n",
      "    config = LesionBoundaryConfig()\n",
      "    config.display()\n",
      "\n",
      "    # initialize the image augmentation process\n",
      "    aug = iaa.SomeOf((0, 2), [\n",
      "    iaa.Fliplr(0.5),\n",
      "    iaa.Flipud(0.5),\n",
      "    iaa.Affine(rotate=(-10, 10))\n",
      "    ])\n",
      "\n",
      "    # initialize the model and load the COCO weights so we can\n",
      "    # perform fine-tuning\n",
      "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
      "    model_dir=LOGS_AND_MODEL_DIR)\n",
      "    model.load_weights(COCO_PATH, by_name=True,\n",
      "    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
      "    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
      "\n",
      "\n",
      "    # train *just* the layer heads\n",
      "    model.train(trainDataset, valDataset, epochs=20,\n",
      "    layers=\"heads\", learning_rate=config.LEARNING_RATE,\n",
      "    augmentation=aug)\n",
      "\n",
      "\n",
      "# check to see if we are investigating our images and masks\n",
      "if args[\"mode\"] == \"investigate\":\n",
      "    # load the training dataset\n",
      "    trainDataset = LesionBoundaryDataset(IMAGE_PATHS, CLASS_NAMES)\n",
      "    trainDataset.load_lesions(trainIdxs)\n",
      "    trainDataset.prepare()\n",
      "\n",
      "    # load the 0-th training image and corresponding masks and\n",
      "    # class IDs in the masks\n",
      "    image = trainDataset.load_image(0)\n",
      "    (masks, classIDs) = trainDataset.load_mask(0)\n",
      "\n",
      "    # show the image spatial dimensions which is HxWxC\n",
      "    print(\"[INFO] image shape: {}\".format(image.shape))\n",
      "\n",
      "    # show the masks shape which should have the same width and\n",
      "    # height of the images but the third dimension should be\n",
      "    # equal to the total number of instances in the image itself\n",
      "    print(\"[INFO] masks shape: {}\".format(masks.shape))\n",
      "\n",
      "    # show the length of the class IDs list along with the values\n",
      "    # inside the list -- the length of the list should be equal\n",
      "    # to the number of instances dimension in the 'masks' array\n",
      "    print(\"[INFO] class IDs length: {}\".format(len(classIDs)))\n",
      "    print(\"[INFO] class IDs: {}\".format(classIDs))\n",
      "\n",
      "    # determine a sample of training image indexes and loop over\n",
      "    # them\n",
      "    for i in np.random.choice(trainDataset.image_ids, 3):\n",
      "        # load the image and masks for the sampled image\n",
      "        print(\"[INFO] investigating image index: {}\".format(i))\n",
      "        image = trainDataset.load_image(i)\n",
      "        (masks, classIDs) = trainDataset.load_mask(i)\n",
      "\n",
      "        # visualize the masks for the current image\n",
      "        visualize.display_top_masks(image, masks, classIDs,\n",
      "            trainDataset.class_names)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "script_folder = './mask_rcnn_horovod'\n",
    "with open(os.path.join(script_folder, './lesions.py'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'currentNodeCount': 4, 'targetNodeCount': 4, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 1, 'idleNodeCount': 3, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-09-09T06:14:05.192000+00:00', 'errors': None, 'creationTime': '2019-09-09T04:29:17.187921+00:00', 'modifiedTime': '2019-09-09T06:07:38.700134+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 4, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow, Mpi\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': datastore.as_mount(),\n",
    "    '--mode': 'train'\n",
    "}\n",
    "\n",
    "\n",
    "est = TensorFlow(source_directory=script_folder,\n",
    "                 script_params=script_params,\n",
    "                 compute_target=compute_target, \n",
    "                 entry_script='lesions.py',\n",
    "                 node_count=3,\n",
    "                 distributed_training=Mpi(),\n",
    "                 framework_version='1.13',\n",
    "                 use_gpu = True,\n",
    "                 pip_packages=['IPython[all]','scikit-image','cython','Pillow','numpy','scipy','azureml-sdk','keras','matplotlib','azureml-dataprep[pandas,fuse]','imgaug','imutils','opencv-python','h5py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.tensorboard import Tensorboard\n",
    "\n",
    "tb = Tensorboard([run])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
