{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/601f4351-33bb-4d76-96ca-886940409b3d/resourceGroups/mlopcent-AML-RG/providers/Microsoft.MachineLearningServices/workspaces/mlopcent-AML-WS',\n",
       " 'name': 'mlopcent-AML-WS',\n",
       " 'location': 'centralus',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'sku': 'Enterprise',\n",
       " 'workspaceid': '9f71fb47-35b4-4cde-9787-6879d312a8e1',\n",
       " 'description': '',\n",
       " 'friendlyName': 'mlopcent-AML-WS',\n",
       " 'creationTime': '2019-11-12T01:09:07.4987878+00:00',\n",
       " 'containerRegistry': '/subscriptions/601f4351-33bb-4d76-96ca-886940409b3d/resourcegroups/mlopcent-aml-rg/providers/microsoft.containerregistry/registries/mlopcentamlcr',\n",
       " 'keyVault': '/subscriptions/601f4351-33bb-4d76-96ca-886940409b3d/resourcegroups/mlopcent-aml-rg/providers/microsoft.keyvault/vaults/mlopcent-aml-kv',\n",
       " 'applicationInsights': '/subscriptions/601f4351-33bb-4d76-96ca-886940409b3d/resourcegroups/mlopcent-aml-rg/providers/microsoft.insights/components/mlopcent-aml-ai',\n",
       " 'identityPrincipalId': '159e1229-ee0a-44ad-9432-149487018400',\n",
       " 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'storageAccount': '/subscriptions/601f4351-33bb-4d76-96ca-886940409b3d/resourcegroups/mlopcent-aml-rg/providers/microsoft.storage/storageaccounts/mlopcentamlsa'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"601f4351-33bb-4d76-96ca-886940409b3d\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"mlopcent-AML-RG\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"mlopcent-AML-WS\")\n",
    "workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"centralus\")\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Create the workspace using the specified parameters\n",
    "ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region,\n",
    "                      create_resource_group = False,\n",
    "                      sku = 'basic',\n",
    "                      exist_ok = True)\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "blob_datastore_name='isic2018' # Name of the Datastore  to workspace\n",
    "container_name=os.getenv(\"BLOB_CONTAINER\", \"isic2018\") # Name of Azure blob container\n",
    "account_name=os.getenv(\"BLOB_ACCOUNTNAME\", \"mlblobdatastore\") # Storage account name\n",
    "account_key=os.getenv(\"BLOB_ACCOUNT_KEY\", \"bPlInBOqf0kfPpSNYeemRKNiOfcWsMWAUfR3ieyTUpxBKn/FEkZG9RgHUQfVjNtI3ky32wZ+LrjCe/oVC9M2eg==\") # Storage account key\n",
    "\n",
    "blob_datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                         datastore_name=blob_datastore_name, \n",
    "                                                         container_name=container_name, \n",
    "                                                         account_name=account_name,\n",
    "                                                         account_key=account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "#get named datastore from current workspace\n",
    "datastore = Datastore.get(ws, datastore_name='isic2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "\n",
    "datastore_paths = [(datastore, 'ISIC2018_Task1-2_Training_Input')]\n",
    "\n",
    "isic_ds_training = Dataset.File.from_files(path=datastore_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new version of titanic_ds\n",
    "isic_ds = isic_ds_training.register(workspace = ws,\n",
    "                                 name = 'isic_ds',\n",
    "                                 description = 'isic training data',\n",
    "                                 create_new_version = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "isic_ds_name = 'isic_inference_data'\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, 'isic_ds')\n",
    "named_isic_ds = dataset.as_named_input(isic_ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/ISIC_0000000.jpg', '/ISIC_0000001.jpg', '/ISIC_0000003.jpg', ...,\n",
       "       '/ISIC_0016070.jpg', '/ISIC_0016071.jpg', '/ISIC_0016072.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the files referenced by mnist dataset\n",
    "dataset.to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "output_dir = PipelineData(name=\"inferences_horovod\", \n",
    "                          datastore=datastore, \n",
    "                          output_path_on_compute=\"ISIC2012_MaskRCNN_Horovod_Inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get('AML_COMPUTE_CLUSTER_NAME', 'cpucluster')\n",
    "compute_min_nodes = os.environ.get('AML_COMPUTE_CLUSTER_MIN_NODES', 0)\n",
    "compute_max_nodes = os.environ.get('AML_COMPUTE_CLUSTER_MAX_NODES', 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get('AML_COMPUTE_CLUSTER_SKU', 'STANDARD_D2_V2')\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                min_nodes=compute_min_nodes, \n",
    "                                                                max_nodes=compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name='mask_rcnn_hvd_finetune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>mask_rcnn_hvd_finetune</td><td>mask_rcnn_hvd_finetune_1577083350_0ceed65a</td><td>azureml.scriptrun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/mask_rcnn_hvd_finetune/runs/mask_rcnn_hvd_finetune_1577083350_0ceed65a?wsid=/subscriptions/601f4351-33bb-4d76-96ca-886940409b3d/resourcegroups/mlserviceworkspace/workspaces/mlserviceworkspace\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: mask_rcnn_hvd_finetune,\n",
       "Id: mask_rcnn_hvd_finetune_1577083350_0ceed65a,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Run\n",
    "run_id = 'mask_rcnn_hvd_finetune_1577083350_0ceed65a'\n",
    "fetched_run = Run(exp, run_id)\n",
    "fetched_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'horovod_model'\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetched_run.get_file_names()\n",
    "fetched_run.download_file('outputs/lesions_logs/lesion20191223T0644/mask_rcnn_lesion_0020.h5', model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model mask_rcnn_horovod\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "# Register the downloaded model \n",
    "model = Model.register(model_path=\"horovod_model/\",\n",
    "                       model_name=\"mask_rcnn_horovod\",\n",
    "                       tags={'model': \"Mask_RCNN_Horovod\",'dataset': \"ISIC_Lesion\"},\n",
    "                       description=\"Mask_RCNN Keras model trained with Horovod\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# import the necessary packages\n",
      "from mrcnn.config import Config\n",
      "from mrcnn import model as modellib\n",
      "from mrcnn import utils\n",
      "import numpy as np\n",
      "import imutils\n",
      "import cv2\n",
      "import os\n",
      "from azureml.core import Model\n",
      "import argparse\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "class LesionBoundaryInferenceConfig():\n",
      "\t# set the number of GPUs and images per GPU (which may be\n",
      "\t# different values than the ones used for training)\n",
      "\tGPU_COUNT = 1\n",
      "\tIMAGES_PER_GPU = 1\n",
      "\n",
      "\t# set the minimum detection confidence (used to prune out false\n",
      "\t# positive detections)\n",
      "\tDETECTION_MIN_CONFIDENCE = 0.9\n",
      "\n",
      "\n",
      "def init():\n",
      "\n",
      "\tglobal model,output_dir\n",
      "\n",
      "\t# construct the argument parser and parse the arguments\n",
      "\tap = argparse.ArgumentParser()\n",
      "\tap.add_argument('--output_dir', type=str, dest='output_dir', help='output dir')\n",
      "\n",
      "\targs = vars(ap.parse_args())\n",
      "\n",
      "\n",
      "\n",
      "# create output directory if it does not exist\n",
      "\n",
      "\toutput_dir = args[\"output_dir\"]\n",
      "\tos.makedirs(output_dir, exist_ok=True)\n",
      "\n",
      "\n",
      "\tLOGS_AND_MODEL_DIR = \"./outputs/lesions_logs\"\n",
      "\tos.makedirs(LOGS_AND_MODEL_DIR, exist_ok=True)\n",
      "\t\n",
      "\tmodel_path = Model.get_model_path(\"mask_rcnn_horovod\")\n",
      "\n",
      "\t# initialize the inference configuration\n",
      "\tconfig = LesionBoundaryInferenceConfig()\n",
      "\n",
      "\t# initialize the Mask R-CNN model for inference\n",
      "\tmodel = modellib.MaskRCNN(mode=\"inference\", config=config,model_dir=LOGS_AND_MODEL_DIR)\n",
      "\n",
      "\n",
      "\tmodel.load_weights(os.path.join(model_path, 'mask_rcnn_lesion_0020.h5'), by_name=True)\n",
      "\n",
      "\n",
      "def run(mini_batch):\n",
      "\n",
      "\tprint(f'run method start: {__file__}, run({mini_batch})')\n",
      "\n",
      "\tresultList = []\n",
      "\t\n",
      "\tfor image_file in mini_batch:\n",
      "\n",
      "\t\tout_filename = os.path.join(output_dir, os.path.basename(image_file))\n",
      "\n",
      "\t\t# load the input image, convert it from BGR to RGB channel\n",
      "\t\t# ordering, and resize the image\n",
      "\t\timage = cv2.imread(image_file)\n",
      "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
      "\t\timage = imutils.resize(image, width=1024)\n",
      "\t\t\n",
      "\t\timage_mask = np.zeros(image.shape())\n",
      "\n",
      "\t\t# perform a forward pass of the network to obtain the results\n",
      "\t\tr = model.detect([image], verbose=1)[0]\n",
      "\n",
      "\t\t# loop over of the detected object's bounding boxes and\n",
      "\t\t# masks, drawing each as we go along\n",
      "\t\tfor i in range(0, r[\"rois\"].shape[0]):\n",
      "\t\t\tmask = r[\"masks\"][:, :, i]\n",
      "\t\t\tfor c in range(3):\n",
      "\t\t\t\timage_mask[:, :, c] = np.where(mask == 1,255,0)\n",
      "\t\t\t\tcv2.imwrite(out_filename, image_mask)\n",
      "\n",
      "\t\t\t\tresultList.append(\"Processed: {}\".format(os.path.basename(image)))\n",
      "\n",
      "\treturn resultList\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "scripts_folder = \"mask_rcnn_horovod_inference\"\n",
    "script_file = \"lesions_inference.py\"\n",
    "\n",
    "# peek at contents\n",
    "with open(os.path.join(scripts_folder, script_file)) as inference_file:\n",
    "    print(inference_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import CondaDependencies, DEFAULT_CPU_IMAGE\n",
    "\n",
    "batch_conda_deps = CondaDependencies.create(pip_packages=['scikit-image','cython','Pillow','numpy','azureml-sdk','tensorflow','keras','azureml-dataprep[pandas,fuse]','imutils','opencv-python','h5py'])\n",
    "\n",
    "batch_env = Environment(name=\"batch_environment\")\n",
    "batch_env.python.conda_dependencies = batch_conda_deps\n",
    "batch_env.docker.enabled = True\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=scripts_folder,\n",
    "    entry_script=script_file,\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=compute_target,\n",
    "    node_count=2,\n",
    "    logging_level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.pipeline.steps import ParallelRunStep\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name=\"batch-lesion-horovod\",\n",
    "    models=[model],\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[named_isic_ds],\n",
    "    output=output_dir,\n",
    "    arguments=[\"--output_dir\", output_dir],\n",
    "    allow_reuse=False\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch-lesion-horovod [edcee79d][c7191358-f868-4bc8-ae69-bef4b7009d06], (This step will run and generate new outputs)\n",
      "Using data reference isic_inference_data_0 for StepId [f09e831a][7ddbde14-8e1c-4980-80a3-f5c45aea1aad], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted PipelineRun e775a8bb-2b16-4155-9a39-96c2db5fa671\n",
      "Link to Azure Machine Learning studio: https://ml.azure.com/experiments/batch_inference_test/runs/e775a8bb-2b16-4155-9a39-96c2db5fa671?wsid=/subscriptions/601f4351-33bb-4d76-96ca-886940409b3d/resourcegroups/mlopcent-AML-RG/workspaces/mlopcent-AML-WS\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "pipeline_run = Experiment(ws, 'batch_inference_test').submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59b847ef8d84854af02426db2e12312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
